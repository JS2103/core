domain: "example.com"
project: "my-gcp-project"
registry: "gcr.io/my-gcp-project"
robots: []

# The default requests/limits are sufficient for small deployments with a few
# robots. For a large deployment with ~30 robots, you might need ~2CPU and
# ~12Gi mem.
# TODO(rodrigoq): can we reduce this by updating prometheus?
limits:
  cpu: "200m"
  memory: "2Gi"
